{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vo3Ak3dJ2e7l",
        "outputId": "15f3ad50-94c5-4053-8277-298d1f6d5553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hiddenLayer1 Weights: [<tf.Variable 'layer0/kernel:0' shape=(32, 18) dtype=float32, numpy=\n",
            "array([[-0.15224564, -0.19484283, -0.29589757,  0.23058116,  0.19104671,\n",
            "        -0.28994882,  0.00730142, -0.06709349,  0.24606222,  0.3215049 ,\n",
            "         0.29039562, -0.0540899 ,  0.01361844, -0.02595162, -0.11765364,\n",
            "        -0.3155937 , -0.3039386 , -0.01864499],\n",
            "       [-0.30734017, -0.02421913,  0.26092333,  0.1673429 , -0.2480017 ,\n",
            "         0.338327  ,  0.11828446, -0.1519403 , -0.20663157,  0.13374412,\n",
            "        -0.22119898, -0.32074   ,  0.2834571 ,  0.16996944, -0.28943032,\n",
            "         0.17720842,  0.04488906,  0.00723875],\n",
            "       [-0.33565718, -0.2971893 , -0.18549663,  0.19906932, -0.31708595,\n",
            "        -0.26826736, -0.15136267, -0.15762122, -0.2630508 , -0.16301711,\n",
            "         0.25895125, -0.10827333,  0.02547622,  0.32782894, -0.17971413,\n",
            "        -0.23165925,  0.05576658, -0.02294424],\n",
            "       [ 0.2837121 ,  0.12586299, -0.13767534,  0.28213608, -0.3214274 ,\n",
            "         0.13110864,  0.31556314,  0.07547724,  0.00510493,  0.01745725,\n",
            "        -0.03381723, -0.29610544,  0.08233088, -0.15271889,  0.23276842,\n",
            "         0.22397172, -0.2500246 ,  0.11107159],\n",
            "       [-0.15339729, -0.16934916,  0.22291404, -0.12932171, -0.12319316,\n",
            "        -0.20493351, -0.20061244, -0.2569798 ,  0.12016085, -0.23050836,\n",
            "         0.03239453, -0.06908077,  0.17977601, -0.29583636, -0.09583971,\n",
            "         0.20208716,  0.21303159,  0.12079424],\n",
            "       [-0.3348668 , -0.2758838 , -0.09084174,  0.21998185,  0.01465034,\n",
            "        -0.28602213, -0.26209676,  0.09253702,  0.33695698, -0.31408164,\n",
            "         0.08630991,  0.01886773, -0.2473532 , -0.14162399,  0.07511097,\n",
            "        -0.27232596, -0.3208227 , -0.05877662],\n",
            "       [-0.09769471, -0.3357348 , -0.23287474,  0.19596422, -0.17445013,\n",
            "         0.03405666, -0.04803246, -0.30203354, -0.21238409,  0.11535811,\n",
            "         0.3454132 , -0.25206771,  0.05619755,  0.04321471,  0.03894395,\n",
            "        -0.21349633,  0.3152796 , -0.24663086],\n",
            "       [ 0.14756423,  0.0917334 , -0.25514597,  0.18625009,  0.00933108,\n",
            "         0.18577588,  0.24540186,  0.01130328,  0.01136175,  0.073264  ,\n",
            "         0.13546687, -0.21074921,  0.24981207,  0.27172   , -0.3388854 ,\n",
            "        -0.3296811 ,  0.13750619, -0.02338991],\n",
            "       [ 0.28689736,  0.02511102,  0.11811227, -0.01520163,  0.2472117 ,\n",
            "        -0.1963497 ,  0.11849168,  0.33487397,  0.33291417,  0.03736854,\n",
            "         0.33947247, -0.29144743, -0.03924936,  0.2297293 ,  0.3030672 ,\n",
            "         0.16983753,  0.06104925, -0.33484963],\n",
            "       [ 0.01167914, -0.2831444 ,  0.13944384,  0.3204986 ,  0.25993901,\n",
            "        -0.33356592,  0.03294283, -0.03642774, -0.32784867,  0.2584861 ,\n",
            "         0.1037761 ,  0.23070943,  0.19662976, -0.1532544 , -0.3333724 ,\n",
            "        -0.12451676,  0.2654807 ,  0.23830146],\n",
            "       [ 0.16582817,  0.3249253 , -0.2193625 , -0.20125219,  0.09049958,\n",
            "        -0.21261723,  0.2294743 ,  0.014103  ,  0.27094412,  0.17400235,\n",
            "        -0.31241256, -0.20358397,  0.00066543,  0.0666109 ,  0.2796601 ,\n",
            "        -0.0797044 , -0.05289045, -0.18607633],\n",
            "       [-0.09437796, -0.31599906,  0.25686687, -0.00162694, -0.30341595,\n",
            "        -0.209141  , -0.00566348,  0.27349204, -0.27608523,  0.16207576,\n",
            "         0.25376463,  0.00943285, -0.16188347,  0.12749025, -0.29870144,\n",
            "        -0.11366484, -0.32080442, -0.22644332],\n",
            "       [ 0.27319264, -0.06460619, -0.0245167 , -0.06058839, -0.29093528,\n",
            "        -0.06918368,  0.31437045,  0.27933228, -0.1579757 ,  0.33439922,\n",
            "        -0.32016888, -0.34595996, -0.21387625,  0.03050533, -0.20175682,\n",
            "         0.231493  , -0.15906061, -0.21785761],\n",
            "       [ 0.00631323,  0.0782035 , -0.13878313,  0.2188515 , -0.16473813,\n",
            "        -0.18355517,  0.11009017,  0.19120556, -0.26304013,  0.08856407,\n",
            "         0.2973249 , -0.12307927, -0.3340446 ,  0.24143255, -0.26751688,\n",
            "        -0.19867924,  0.06196758, -0.33794305],\n",
            "       [ 0.13591722,  0.0375143 , -0.28575867, -0.17580165, -0.15991831,\n",
            "        -0.1289166 , -0.26307473,  0.2647339 , -0.20165697,  0.23164892,\n",
            "         0.06802833,  0.04215118,  0.07529953, -0.08278519, -0.12569366,\n",
            "        -0.19688967,  0.25892556, -0.32379594],\n",
            "       [ 0.0917567 , -0.1380446 , -0.01656404,  0.3285557 ,  0.0582605 ,\n",
            "         0.14725518, -0.33602148, -0.29242083,  0.23968005,  0.329866  ,\n",
            "         0.17002815,  0.11481631, -0.0946804 , -0.10909435, -0.32462028,\n",
            "         0.20417655,  0.07782564,  0.18891925],\n",
            "       [ 0.08336219, -0.33977994,  0.31478143, -0.33504453,  0.09730628,\n",
            "         0.23385435, -0.00157219,  0.08893695,  0.14979988, -0.19592518,\n",
            "        -0.34205648, -0.07777485, -0.14409313, -0.29439327, -0.21814577,\n",
            "         0.3396824 ,  0.04692039,  0.28966063],\n",
            "       [ 0.24306685,  0.17790765, -0.2132745 , -0.22588831, -0.13565005,\n",
            "        -0.03151989,  0.18717933,  0.06206775,  0.2051025 , -0.08635849,\n",
            "         0.05430424,  0.25969982, -0.01331684, -0.23355767, -0.32836294,\n",
            "         0.1825195 ,  0.29729515, -0.1597414 ],\n",
            "       [-0.2659574 ,  0.18129921,  0.09631065, -0.22222179,  0.08145928,\n",
            "        -0.11060254,  0.09617901,  0.03601158, -0.13958491, -0.10980803,\n",
            "        -0.28816518, -0.07767376, -0.15560667,  0.15103066,  0.02962419,\n",
            "         0.01850659,  0.15093055, -0.14136516],\n",
            "       [ 0.05264995,  0.24454314,  0.18096507, -0.10342839, -0.0833545 ,\n",
            "        -0.04931322, -0.2868789 , -0.20799002, -0.22011961,  0.29641968,\n",
            "         0.05529732,  0.12786177,  0.24887675,  0.1485464 ,  0.11266774,\n",
            "        -0.02836615, -0.19598654,  0.05995971],\n",
            "       [ 0.28257972, -0.31684372, -0.21912414, -0.14291811, -0.05162871,\n",
            "         0.0583055 ,  0.0158346 , -0.32949775,  0.07752377, -0.29913092,\n",
            "        -0.02304527,  0.10857677,  0.04250294, -0.3423585 , -0.1748563 ,\n",
            "         0.25675994, -0.18706048,  0.0736168 ],\n",
            "       [-0.21464574,  0.14394313, -0.04815271,  0.17802286, -0.31769323,\n",
            "        -0.19482945, -0.1332408 ,  0.23710346, -0.17778547,  0.04590699,\n",
            "         0.20732152,  0.14063975,  0.02564594, -0.14614607, -0.25757453,\n",
            "         0.3097325 ,  0.12413973, -0.15690178],\n",
            "       [-0.24539763,  0.02199569, -0.15152314, -0.20864852, -0.21892527,\n",
            "        -0.2787078 ,  0.07717308,  0.07132179,  0.1465464 , -0.17935444,\n",
            "        -0.15411517,  0.01165015, -0.30661264, -0.3326365 , -0.21066034,\n",
            "         0.2622941 ,  0.0221408 , -0.10637456],\n",
            "       [ 0.1817109 ,  0.02137148,  0.3182153 , -0.292866  ,  0.08833984,\n",
            "        -0.18138205,  0.31667215, -0.31339514, -0.3004588 , -0.32441503,\n",
            "         0.0328837 ,  0.06107178, -0.06600815, -0.0328258 ,  0.11785638,\n",
            "        -0.09741646, -0.21823134,  0.20393306],\n",
            "       [-0.30636132, -0.32475942,  0.17303997,  0.1881687 ,  0.12073633,\n",
            "         0.06422347,  0.23040289,  0.33743465, -0.24572128,  0.132451  ,\n",
            "         0.31162256,  0.19622648, -0.31475928, -0.115389  ,  0.22128445,\n",
            "        -0.2582991 , -0.05728155, -0.27733994],\n",
            "       [-0.27330822,  0.23022127, -0.0904738 , -0.27164897, -0.07583603,\n",
            "         0.10892966, -0.27528858,  0.10378039, -0.12646061,  0.31355578,\n",
            "         0.14062664, -0.03067639, -0.26931074, -0.30141264,  0.01143193,\n",
            "        -0.2980286 ,  0.306239  ,  0.24141312],\n",
            "       [-0.15775889,  0.1575895 ,  0.28030014,  0.23505056,  0.21868771,\n",
            "         0.07959953,  0.1760248 ,  0.19810522, -0.00477117,  0.28938258,\n",
            "        -0.0410296 ,  0.14965767, -0.1270499 , -0.05195677,  0.1435397 ,\n",
            "        -0.11722541,  0.07363665, -0.10940582],\n",
            "       [-0.19431078,  0.3326584 ,  0.11450157,  0.29567975,  0.17773896,\n",
            "        -0.04646465,  0.09487274,  0.24004763, -0.04767776, -0.27264014,\n",
            "         0.25685543, -0.33221737,  0.18445128, -0.12878612, -0.33512828,\n",
            "        -0.13549966,  0.29852897, -0.12444828],\n",
            "       [-0.12683408, -0.2657904 ,  0.04032114, -0.28481522, -0.24983233,\n",
            "        -0.03803083,  0.17340088,  0.06201318,  0.04810673, -0.26659828,\n",
            "        -0.3441125 , -0.19043654,  0.21985137, -0.34191823,  0.15997791,\n",
            "         0.19163263, -0.06130248, -0.07350233],\n",
            "       [ 0.30708498,  0.22142857,  0.15058821, -0.23596966, -0.03269118,\n",
            "         0.06475988, -0.20193158,  0.04404566, -0.3450035 , -0.10550703,\n",
            "         0.24856275,  0.3131082 , -0.1561649 , -0.22505835, -0.19355302,\n",
            "         0.13628417, -0.12633325,  0.05965444],\n",
            "       [-0.2586706 ,  0.05036715,  0.11230153, -0.04202607,  0.03820065,\n",
            "         0.12188914, -0.04759979, -0.01007128,  0.08897313,  0.09316832,\n",
            "        -0.0374409 ,  0.31676608,  0.1195173 , -0.04532531,  0.09950426,\n",
            "        -0.07845777,  0.31511348,  0.13694367],\n",
            "       [ 0.20738906,  0.1655013 ,  0.10455337,  0.27703106,  0.0990316 ,\n",
            "         0.08622476,  0.34256285, -0.2848058 ,  0.2355473 ,  0.08723807,\n",
            "         0.03010601,  0.27990514,  0.2694888 , -0.24198267,  0.19430721,\n",
            "        -0.20142448,  0.21016043, -0.21045245]], dtype=float32)>, <tf.Variable 'layer0/bias:0' shape=(18,) dtype=float32, numpy=\n",
            "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "       0.], dtype=float32)>]\n",
            "hiddenLayer2 Weights: [<tf.Variable 'layer1/kernel:0' shape=(18, 9) dtype=float32, numpy=\n",
            "array([[-0.47063655, -0.16712451,  0.28106406,  0.36651418, -0.08193538,\n",
            "         0.37178656, -0.19075787,  0.2849699 , -0.07952514],\n",
            "       [ 0.02918306, -0.33353317, -0.3934849 , -0.2583494 , -0.38646895,\n",
            "        -0.05368441, -0.02276313, -0.4104957 , -0.08750394],\n",
            "       [-0.14159185,  0.38757983, -0.38823935, -0.16946775, -0.28005368,\n",
            "        -0.05323192, -0.4358317 , -0.16541436, -0.39247382],\n",
            "       [-0.429139  , -0.20162693, -0.01441848, -0.03888121, -0.44171977,\n",
            "        -0.06979361, -0.13944045, -0.34211126, -0.14509115],\n",
            "       [-0.24295916,  0.31149724, -0.26872247,  0.21334341, -0.4181144 ,\n",
            "        -0.1834332 , -0.4079643 , -0.10704458,  0.00215882],\n",
            "       [-0.09493303,  0.03805164,  0.07108465,  0.27914217,  0.22943428,\n",
            "        -0.37701178,  0.16984382, -0.14164397,  0.1411989 ],\n",
            "       [-0.45670113, -0.33414304, -0.31337273,  0.235877  , -0.05015543,\n",
            "        -0.21219623, -0.30312172,  0.13854846, -0.4084077 ],\n",
            "       [ 0.13135925, -0.12412223, -0.17334303, -0.45905662, -0.26910728,\n",
            "        -0.20990446,  0.3485045 ,  0.10631087, -0.26696545],\n",
            "       [ 0.32908306,  0.30479726,  0.21271786, -0.29025555, -0.04970753,\n",
            "         0.43535236, -0.33480793,  0.30156174,  0.14525267],\n",
            "       [-0.21014485, -0.2040847 , -0.04295945, -0.19285679,  0.33258596,\n",
            "        -0.32976368,  0.23925295, -0.31712234,  0.22964528],\n",
            "       [-0.4026484 ,  0.36510083, -0.24248217, -0.40657356,  0.37833425,\n",
            "         0.16586182, -0.28007144, -0.26435795, -0.3562284 ],\n",
            "       [ 0.09333345,  0.40228572, -0.14240769,  0.21337566, -0.17377281,\n",
            "         0.44308946, -0.2649848 , -0.3972963 ,  0.24058387],\n",
            "       [-0.45971546,  0.19205096,  0.30544707, -0.32039237, -0.2570171 ,\n",
            "         0.15394077, -0.10334924, -0.34265232,  0.39641348],\n",
            "       [-0.4225407 , -0.37901145,  0.15805808, -0.3532005 , -0.380465  ,\n",
            "         0.4053965 , -0.2685995 ,  0.40816686, -0.01701969],\n",
            "       [ 0.21993348, -0.12682381, -0.10163021,  0.45731714,  0.24921748,\n",
            "        -0.41642368,  0.17742744, -0.12303093,  0.087975  ],\n",
            "       [ 0.12260339, -0.46526536, -0.1906746 ,  0.24246427, -0.01477185,\n",
            "        -0.11138737,  0.2782525 ,  0.34957394,  0.38125905],\n",
            "       [ 0.32364687,  0.23553118,  0.14483097, -0.0551337 , -0.00627717,\n",
            "         0.34948584, -0.3296824 ,  0.2947763 ,  0.22392675],\n",
            "       [-0.08443868,  0.135667  ,  0.00974289,  0.2588909 , -0.24917892,\n",
            "        -0.21539399, -0.17390913,  0.04259303,  0.06152889]],\n",
            "      dtype=float32)>, <tf.Variable 'layer1/bias:0' shape=(9,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]\n",
            "OutputLayer Weights: [<tf.Variable 'outputlayer/kernel:0' shape=(9, 1) dtype=float32, numpy=\n",
            "array([[-0.75741476],\n",
            "       [-0.15092051],\n",
            "       [-0.37566748],\n",
            "       [-0.03944081],\n",
            "       [-0.6477395 ],\n",
            "       [-0.7023288 ],\n",
            "       [ 0.04206824],\n",
            "       [-0.29740492],\n",
            "       [ 0.6775217 ]], dtype=float32)>, <tf.Variable 'outputlayer/bias:0' shape=(1,) dtype=float32, numpy=array([0.], dtype=float32)>]\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2930 - accuracy: 0.5063\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2347 - accuracy: 0.7405\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2047 - accuracy: 0.7405\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 7ms/step - loss: 0.2576 - accuracy: 0.4810\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.7405\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.8500\n",
            "For  0 th cross validation: error/loss and accuracy are as follows:  [0.13118919730186462, 0.8500000238418579]\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.7405\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.7405\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2482 - accuracy: 0.7405\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.2483 - accuracy: 0.7405\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.7405\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1397 - accuracy: 0.8500\n",
            "For  1 th cross validation: error/loss and accuracy are as follows:  [0.13967765867710114, 0.8500000238418579]\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2390 - accuracy: 0.7405\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2249 - accuracy: 0.7405\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.1975 - accuracy: 0.7405\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2038 - accuracy: 0.7405\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 0.2142 - accuracy: 0.7405\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1438 - accuracy: 0.8500\n",
            "For  2 th cross validation: error/loss and accuracy are as follows:  [0.14377489686012268, 0.8500000238418579]\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1937 - accuracy: 0.7405\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2104 - accuracy: 0.7405\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.2125 - accuracy: 0.7405\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 4ms/step - loss: 0.2030 - accuracy: 0.7405\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1925 - accuracy: 0.7405\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.1489 - accuracy: 0.8500\n",
            "For  3 th cross validation: error/loss and accuracy are as follows:  [0.14894196391105652, 0.8500000238418579]\n",
            "Epoch 1/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1934 - accuracy: 0.7405\n",
            "Epoch 2/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1920 - accuracy: 0.7405\n",
            "Epoch 3/5\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1930 - accuracy: 0.7405\n",
            "Epoch 4/5\n",
            "3/3 [==============================] - 0s 5ms/step - loss: 0.1939 - accuracy: 0.7405\n",
            "Epoch 5/5\n",
            "3/3 [==============================] - 0s 6ms/step - loss: 0.1935 - accuracy: 0.7405\n",
            "2/2 [==============================] - 0s 8ms/step - loss: 0.1426 - accuracy: 0.8500\n",
            "For  4 th cross validation: error/loss and accuracy are as follows:  [0.14259396493434906, 0.8500000238418579]\n",
            "Average accuracy for 5-fold validation:  0.8500000238418579\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import sklearn\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import optimizers\n",
        "bc_dataset = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wpbc.data\",header=None)\n",
        "bc_dataset[1].replace({'N':1,'R':0}, inplace=True)\n",
        "input_data = bc_dataset.iloc[:, 2:-1]\n",
        "input_labels = bc_dataset.iloc[:, 1]\n",
        "\n",
        "cnnModel = Sequential()\n",
        "hiddenLayer1=Dense(18, activation = 'sigmoid',name=\"layer0\",input_shape = (32,))\n",
        "hiddenLayer2=Dense(9, activation = 'sigmoid',name=\"layer1\")\n",
        "outputLayer=Dense(1, activation = 'sigmoid',name=\"outputlayer\")\n",
        "cnnModel.add(hiddenLayer1)\n",
        "cnnModel.add(hiddenLayer2)\n",
        "cnnModel.add(outputLayer)\n",
        "print(\"hiddenLayer1 Weights:\", hiddenLayer1.weights)\n",
        "print(\"hiddenLayer2 Weights:\", hiddenLayer2.weights)\n",
        "print(\"OutputLayer Weights:\", outputLayer.weights)\n",
        "cnnModel.compile(optimizer = optimizers.Adam(learning_rate = 0.5), loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "sum=0;\n",
        "for i in range(5):\n",
        "  train_dt, test_dt, train_labels, test_labels = sklearn.model_selection.train_test_split(input_data, input_labels, test_size=0.2,shuffle=True, random_state=9);\n",
        "  train_dt = sklearn.preprocessing.normalize(train_dt)\n",
        "  test_dt = sklearn.preprocessing.normalize(test_dt)\n",
        "  cnnModel.fit(train_dt,train_labels.values, batch_size = 75, epochs = 5, verbose = 1)\n",
        "  test_dt = sklearn.preprocessing.normalize(test_dt)\n",
        "  outputInfo = cnnModel.evaluate(test_dt, test_labels.values)\n",
        "  print(\"For \",i,\"th cross validation: error/loss and accuracy are as follows: \",outputInfo)\n",
        "  sum+=outputInfo[1];\n",
        "\n",
        "print(\"Average accuracy for 5-fold validation: \",sum/5);"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "7LT-Gpg0avPa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}